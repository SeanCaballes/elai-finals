Section
1,
Week
1:
Introduction
to
Artificial
Intelligence
(LEC)
I.
Overview
of
AI:
Definitions
and
History
●
Data
explosion
We
live
in
a
world
with
an
ever
increasing
amount
of
data
that
both
humans
and
machines
generate.
It
far
outpaces
humans'
ability
to
extract
meaningful
information
and
make
informed
and
complex
decisions
based
on
the
extensive
data
to
process.
Every
day,
we
create
roughly
2.5
quintillion
bytes
of
data
(that's
2.5,
followed
by
a
staggering
18
zeros!)
We
may
not
be
aware,
but
we
have
been
using
Artificial
Intelligence
based
technologies
in
our
daily
routine.
Scientists
found
that
an
average
person
today
can
process
as
much
as
74
gigabytes
(GB)
of
data
a
day.
Artificial
Intelligence
is
a
technology
that
is
transforming
every
walk
of
life
with
its
five
basic
components
including
learning,
reasoning,
problem-solving,
perception,
and
language
understanding.
What
is
a
machine?
A
machine
is
a
piece
of
equipment
with
moving
parts
that
humans
design
to
do
a
particular
job.
A
machine
usually
needs
electricity,
gas,
steam,
and
so
on
to
work.
What
is
a
computer?
A
computer
is
an
electronic
machine
that
can
store,
find
and
arrange
information,
calculate
amounts,
and
control
other
machines.●
What
is
Artificial
Intelligence
(AI)?
○
The
human
brain
has
the
ability
to
think,
read,
learn,
remember,
reason,
and
pay
attention.
Such
capabilities
are
termed
cognitive
skills.
The
term
“
Intelligence
”
is
used
for
cognitive
(connected
with
the
processes
of
understanding)
skills
and
thinking
ability
of
humans
and
animals.
We
may
also
call
it
“natural
intelligence.”
○
Then
what
is
Artificial
Intelligence
(referred
to
as
AI
in
the
remaining
book)?
○
The
terminology
comprises
two
words
“
Artificial
”
and
“
Intelligence
.”
Artificial
refers
to
something
that
is
not
natural
or
is
made
by
humans.
AI
is,
then,
intelligence
demonstrated
by
a
computer
(an
electronic
machine),
hence,
it
can
also
be
referred
to
as
“machine
intelligence.”
○
In
other
words,
AI
is
best
described
as
machines
having
human-like
cognitive
skills
of
learning
and
problem
solving
by
making
decisions
in
such
a
way
that
they
can
be
associated
with
human
minds.
○
To
summarize,
AI
is
a
field
of
computer
science
(not
science
fiction)
combining
robust
datasets
with
the
aim
of
having
computers
simulate
intelligent
processes.
Here
the
computer
needs
AI
implemented
in
its
system
to
demonstrate
AI
capabilities.
○
Today
AI
contributes
much
to
our
human
lives.
Industries,
including
retail,
healthcare,
manufacturing,
agriculture,
insurance,
and
finance,
are
already
harnessing
the
many
benefits
of
AI.
There
are
companies
that
provide
AI
solutions,
while
others
use
AI
within
their
organization
to
manage
internal
business
operations
or
business
growth.
A
few
real
world
companies
in
the
preceding
categories
will
be
described
by
the
end
of
this
book.
●
Artificial
Intelligence:
History
and
evolution:
○
Artificial
Intelligence
(AI)
has
been
studied
for
decades
and
is
still
one
of
the
most
elusive
subjects
in
Computer
Science.○
The
year
1943:
Warren
McCulloch
and
Walter
pits
1943
proposed
a
model
of
artificial
neurons.
○
The
year
1949:
Donald
Hebb
demonstrated
modifying
the
connection
strength
between
neurons.
His
rule
is
now
called
Hebbian
learning.
○
The
year
1950:
Alan
Turing,
an
English
mathematician,
pioneered
Machine
learning
in
1950.
Alan
Turing
proposed
a
test
in
his
"Computing
Machinery
and
Intelligence"
publication.
The
test,
called
a
Turing
test,
can
check
the
machine's
ability
to
exhibit
intelligent
behavior
equivalent
to
human
intelligence.
○
The
period
between
the
1950s
and
the
1970s
revolved
around
the
research
on
neural
networks;
the
following
three
decades
(1980s
to
2010s)
were
the
development
of
the
applications
of
Machine
Learning.
○
In
Figure
1.1,
a
brief
timeline
of
the
past
six
decades
of
how
AI
evolved
from
its
inception
has
been
depicted:
●
The
father
of
AI
John
McCarthy
is
widely
recognized
as
the
“
Father
of
Artificial
Intelligence
”
due
to
his
astounding
contribution
and
innovations
in
the
field
of
Computer
Science
and
AI.
John
McCarthy
coined
the
term
“Artificial
Intelligence”
in
his
1955
proposal
for
the
1956
Dartmouth
Summer
Research
Project
,
the
first
artificial
intelligence
conference,
which
was
a
seminal
event
for
artificial
intelligence
as
a
field.
Refer
to
Figure
1.2
which
depicts
the
proposal
where
the
term
Artificial
Intelligence
was
coined:
In
his
proposal,
he
stated
that
the
conference
was
"to
proceed
on
the
basis
of
the
conjecture
that
every
aspect
of
learning
or
any
other
feature
of
intelligence
can
in
principle
be
so
precisely
described
that
a
machine
can
be
made
to
simulate
it."
In
1956,
for
the
first
time,
Artificial
Intelligence
was
coined
as
an
academic
field.
The
researchers
thought
about
ways
to
make
machines
more
cognizant,
and
they
wanted
to
lay
out
a
framework
to
better
understand
human
intelligence.
John
also
paved
the
way
for
a
few
of
the
world’s
technological
innovations
like
programming
languages,
the
Internet,
the
web,
and
robots,
to
name
just
a
few
He
invented
the
first
programming
language
for
symbolic
computation,
LISP,
and
invented
and
established
time-sharing.
Human-level
Artificial
Intelligence
and
common-sense
reasoning
were
two
of
his
major
contributions.
II.
Types
of
Artificial
Intelligence
Artificial
Intelligence
can
be
classified
into
two
types:
●
Based
on
the
capabilities
of
AI
○
Artificial
narrow
intelligence
Artificial
narrow
intelligence,
ANI
or
Narrow
AI,
also
called
“Weak”
AI,
is
goal
oriented
and
is
designed
to
perform
singular
tasks
intelligently
and
extremely
well
without
any
human
intervention.
Language
translation
and
image
recognition
are
examples
of
common
uses
for
narrow
AI.
Siri
is
capable
of
processing
human
language
and
submitting
a
request
to
a
search
engine
for
retrieval.
It
explains
why
Siri
is
unable
to
answer
abstract
and
complex
queries
that
require
emotional
intelligence.
It’s
mere
digital
assistance
to
perform
basic
inquiries
and
tasks.Even
if
Narrow
AI
appears
to
be
considerably
more
sophisticated,
it
operates
within
a
predetermined,
predefined
scope.
It
can
attend
to
a
task
in
real-time,
but
they
pull
information
from
a
specific
dataset.
In
fact,
what
may
appear
as
a
complicated
AI
as
a
self-driving
automobile
is
labeled
Weak
AI.
Narrow
AI
is
unable
to
think.
They
lack
the
capability
for
autonomous
reasoning,
self-awareness,
consciousness,
and
genuine
intelligence.
●
Artificial
general
intelligence
Artificial
general
intelligence
(AGI)
,
also
called
“Strong”
AI,
is
an
intelligent
system
with
comprehensive
or
complete
knowledge
and
cognitive
computing
capabilities.
In
today’s
world,
no
true
AGI
systems
exist
and
remain
the
stuff
of
science
fiction.
Sci-fi
movies
like
“Her,”
where
a
human
interacts
with
a
machine
displaying
broad
intellectual
capabilities
to
learn,
reason,
and
make
their
own
decisions
and
judgments,
while
understanding
belief
systems.
True
AGI
intellectual
capacities
would
exceed
human
capacities
because
of
its
systems’
ability
to
process
huge
data
sets
at
incredible
speeds.
Hence,
no
real-world
systems
as
examples
here.
https://youtu.be/DQacCB9tDaw
https://youtu.be/fXY1waoj2ns
●
Artificial
super
intelligence
Artificial
superintelligence,
or
ASI,
will
be
human
intelligence
in
all
aspects.
ASI
is
a
futuristic
notion
and
idea
about
AI
capabilities
to
supersede
human
intelligence.
It
will
be
self-aware
and
intelligent
enough
to
surpass
the
cognitive
abilities
of
humans.
OpenAI's
Unveils
Shocking
Plan:
Artificial
Super
Intelligence
(ASI)
is
Coming!
https://youtu.be/-m84CvUuL9c
Many
are
concerned
about
ASI
and
its
impact
on
humankind.
Individuals
like
Tesla
CEO
Elon
Musk
warned
about
the
dangers
of
ASI-powered
robots,
even
predicting
“scary
outcomes”
like
in
<the
movie>
“The
Terminator.”
●
Based
on
the
functionality
of
AI
AI
can
primarily
be
divided
into
four
different
categories
based
on
functionality.
Let
us
have
a
look
at
each:
●
Reactive
AI
These
machines
are
the
most
basic
type
of
AI
system
and
perform
best
when
all
parameters
are
known.
These
machines
do
not
have
any
memory
or
understanding
of
historical
data
and
will
not
perform
desirably
in
case
of
imperfect
information
input.
Refer
to
Figure
1.3:
These
are
good
for
simple
classification
and
pattern
recognition
tasks
where
they
specialize
in
just
one
field
of
work
and
can
beat
humans
by
their
capacities
to
make
faster
calculations.
For
example,
in
a
chess
game,
the
machine
observes
the
opponents’
moves
and
makes
the
best
possible
decision
toward
its
win.
This
means
reactive
machines
always
respond
to
identical
situations
in
the
exact
same
way
every
time.
Face
recognition
is
another
example.
●
Limited
memory
Limited
memory
AI
can
complete
complex
classification
tasks
and
uses
historical
data
to
make
predictions.
They
keep
building
on
their
memory,
that
is,
storing
the
previous
data
and
predictions,
but
memory
is
minimal.
Refer
to
Figure
1.4:
For
example,
this
machine
can
suggest
a
restaurant
based
on
the
location
data,
food
preference,
and
other
such
parameters
that
have
been
gathered.
Self-driving
cars
are
limited
memory
AI.
These
use
sensors
to
identify
humans
and
animals
crossing
the
road,
obstacles
on
the
path,
steep
roads,
traffic
signals,
and
so
on
to
make
better
driving
decisions.
●
Theory
of
Mind
A
robot
or
a
system
powered
by
the
Theory
of
Mind
AI
will
be
able
to
communicate
deeper
with
human
beings
with
its
ability
to
understand
thoughts,
emotions,
and
feelings
and
adjust
its
behavior
(social
interaction)
in
accordance.
Refer
to
Figure
1.5:
Such
robots/systems
will
be
able
to
explain
their
actions,
and
this
is
different
from
the
current
generation
of
AI.
Theory
of
Mind
AI-powered
systems
will
be
able
to
simulate
the
consequences
of
their
actions.
A
new
study
describes
a
robot
that
can
predict
how
another
robot
will
behave,
a
first
step
in
developing
the
so-called
Theory
of
Mind
However,
a
machine
based
on
this
type
is
yet
to
be
built
in
its
entirety.
●
Self-aware
Self-aware
machines
are
the
future
generation
of
these
new
AI
technologies.
No
such
system
is
yet
known
to
have
been
developed
that
possesses
intelligence,
is
sentient,
and
is
conscious.
Such
self-aware
systems
will
be
able
to
interact
with
and
understand
both
humans
and
other
AIs.
Refer
to
Figure
1.6:
III.
Key
Concepts:
Machine
Learning,
Deep
Learning,
and
Neural
Networks
●
Machine
Learning
(ML)
○
What
is
machine
learning?
Machine
learning
is
a
method
of
data
analysis
that
brings
automation
to
analytical
model
building.
It
is
a
branch
of
artificial
intelligence
based
on
the
idea
that
systems
can
learn
on
their
own
from
data
without
being
explicitly
programmed.
The
iterative
aspect
of
machine
learning
is
important
because
as
the
system
is
exposed
to
new
data,
it
is
able
to
adapt
independently.
They
learn
from
previous
behavior
to
produce
reliable,
repeatable
decisions
and
results.
It’s
not
a
new
science–
but
it
has
gained
fresh
momentum.
It
is
an
application
of
AI
that
provides
the
system
the
ability
to
automatically
learn
and
improve
from
experience,
that
is
integrating
the
output
back
into
the
system.
Refer
to
Figure
1.7.
This
figure
describes
the
difference
between
traditional
programming
and
machine
learning.
While
traditional
programming
involves
a
computer
running
a
program
with
input
data
and
giving
an
output.
Machine
learning
includes
the
input
and
its
output
fed
again
into
the
program
which
may
continuously
train
itself
based
on
the
available
data.
Examples
●
Recognition
○
Image
recognition
:
Law
enforcement
uses
machine
learning-based
image
recognition
tools
to
identify
faces
by
matching
them
against
a
database
of
people.
○
Speech
recognition
:
We
may
have
used
voice
dialing
or
giving
voice
inputs
to
smartphones
for
google
searches.
This
is
also
based
on
machine
learning
algorithms.
○
Medical
diagnosis
:
Now,
many
physicians
have
started
to
use
chatbots
with
speech
recognition
capabilities
to
discern
patterns
in
patients’
symptoms
and
help
diagnose
diseases.
●
Distances
○
Google
Maps
:
Google
Maps
does
real-time
data
tracking
by
informing
passengers
of
traffic
and
obstacles
on
the
path.
It
was
in
form
of
the
crowdiest
and/or
the
shortest
routes.
These
features
are
machine
learning-
enabled.
○
Ride
apps
:
Ride
apps
like
Uber
use
machine
learning
to
forecast
the
expected
arrival
time
by
taking
real-time
traffic,
GPS
data,
and
Map
APIs
as
input.
●
Email
intelligence
○
Spam
:
Ever
wonder
what
few
emails
go
into
the
spam
folder?
These
are
filtered
on
the
basis
of
machine
learning
algorithms
used
by
email
providers.
○
Email
classification
:
The
classification
of
emails,
say
by
Gmail,
into
Primary,
Promotions,
Social,
and
so
on
is
also
done
using
machine
learning
by
Gmail.
○
Suggested
Smart
replies
:
Google
email
-
Gmail
recently
also
started
suggesting
smart
replies
based
on
the
content
of
the
email
for
better
user
experience
and
delight.
These
responses
are
customized
per
email
too.
●
Social
networking
apps
○
Facebook
:
Facebook
automatically
reflects
faces
and
suggests
friends
tag
while
uploading
a
pic.
Facebook
uses
AI
and
ML
to
identify
faces.
What
is
data?
The
most
vital
ingredient
in
machine
learning
and
AI
is
the
information
fed
to
the
systems
to
build
intelligent
models.
Data
refers
to
information
that
has
been
converted
into
a
form
that
is
more
efficient
for
storing,
processing,
and
transferring.Data
may
be
structured
or
unstructured,
and
is
collected
and
stored
in
a
format
that
makes
it
faster
to
be
measured,
reported,
visualized,
and
analyzed.
In
contrast,
raw
data
is
a
term
used
to
describe
data
in
its
most
basic
digital
format.
Following
are
some
examples
of
data:
●
Deep
Learning:
What
is
Deep
learning?
Deep
learning
is
a
subset
of
machine
learning.
It
is
a
machine
learning
algorithm
that
uses
deep
(more
than
one
layer)
neural
networks
to
analyze
data
and
provide
output
attaining
the
highest
rank
in
terms
of
accuracy
when
it
is
trained
with
a
large
amount
of
data.
The
main
difference
between
deep
and
machine
learning
is,
machine
learning
models
become
better
progressively
but
the
model
still
needs
some
guidance.
As
in,
the
programmer
needs
to
fix
that
problem
explicitly
in
case
of
inaccurate
outcomes.
But
in
the
case
of
deep
learning,
the
model
does
feature
extraction
independently.
Examples
●
Chatbots
:
Siri,
which
is
Apple’s
voice-controlled
virtual
assistant.
Is
based
on
Deep
Learning
and
gets
smarter
day
by
day
by
adapting
itself
according
to
the
user
and
providing
better-personalized
assistance.
●
Self-driving
/
automatic
cars
:
These
are
also
examples
of
deep
learning.
●
Google
AI
Eye
Doctor
:
One
of
the
initiatives
from
Google
is
Automated
Retinal
Disease
Assessment
or
ARDA
which
uses
artificial
intelligence
and
deep
learning
to
help
healthcare
workers
detect
diabetic
retinopathy.
●
AI-based
based
music
composers
and
platforms
such
as
Aiva,
Amper
and
Ecrett
Music,
and
so
on
are
built
using
detailed
algorithms
that
process
the
inputs
of
its
users.
The
smart
platform
efficiently
concocts
a
piece
of
music
that
totally
fits
users’
criteria,
based
on
a
library
of
musicological
knowledge,
and
builds
stirring
music
instantly.
●
AI
Dream
Reader
:
A
group
of
researchers
from
the
University
of
Kyoto
in
Japan
used
machine
learning
to
study
brain
scans
or
analysis
of
human
functional
magnetic
resonance
imaging,
where
it
could
also
generate
visualizations
of
what
a
person
is
thinking
when
referring
to
simple,
binary
images.
They
then
used
deep
learning
/
deep
neural
networks
to
decode
thoughts.
Once
this
technology
develops
further,
it
can
allow
drawing
pictures,
can
visualize
human
dreams,
hallucinations
of
psychiatric
patients,
and
much
more.
Machine
learning
techniques
and
training
Machine
learning
uses
three
techniques
that
teach
computers
to
do
what
comes
naturally
to
humans
and
animals-learn
from
the
experience:Let’s
understand
these
three
models:
○
Supervised
learning
Supervised
learning
trains
a
model
on
known
input
and
output
data
to
predict
future
outputs.
Refer
to
Figure
1.11:
●
Unsupervised
learning
Unsupervised
learning
uses
hidden
patterns
or
internal
structures
in
the
input
data.
Refer
to
Figure
1.12:
Example:
Sorting
flowers
from
leaves
and
forming
two
clusters.
Refer
to
Figure
1.13:
●
Reinforcement
learning
Reinforcement
learning
is
based
on
rewarding
desired
behaviors
and/or
punishing
undesired
ones.
In
other
words,
use
a
reward
system
to
train
the
model.
Refer
to
Figure
1.14.
Example:
A
dog
learning
and
unlearning
actions
and
skills
based
on
a
reward
mechanism.
Refer
to
Figure
1.15:
The
following
table
highlights
the
major
differences
between
the
learning
methodologies:
●
Neural
Networks:
Neural
networks
refer
to
systems
of
neurons,
either
organic
or
artificial
in
nature.
In
regards
to
AI,
it
refers
to
a
series
of
algorithms
that
aims
at
recognizing
underlying
relationships
and
patterns
in
a
set
of
data
through
a
process
that
imitates
the
way
the
human
brain
operates.
At
its
heart,
it
is
just
multiplication
and
differentiation.
As
such,
neural
networks
can
help
systems
make
intelligent
decisions
with
limited
human
supervision
simply
because
they
can
learn
and
model
the
relationships
between
input
and
output
data
that
are
nonlinear
and
complex.
An
Artificial
Neural
Network
is
made
up
of
3
components:
●
Input
layer
●
Hidden
(computation)
layers
●
Output
layer
In
neural
networks,
learning
happens
in
two
steps:
●
Forward-Propagation
Helps
in
making
a
guess
about
the
answer.
As
the
name
suggests,
the
input
data
is
fed
in
the
forward
direction,
each
hidden
layer
accepts
the
input
data,
processes
it
as
per
the
activation
function,
and
passes
it
to
the
successive
layer.
●
Back-Propagation
It
is
the
short
form
for
“backward
propagation
of
errors.”
Backpropagation
is
the
process
of
tuning
a
neural
network's
weights
(input
is
modeled
using
randomly
selected
weights)
to
better
the
prediction
accuracy,
minimizing
the
error
between
the
actual
answer
and
guessed
answer.
What
machine
learning
can
and
cannot
do
As
per
Wikipedia,
Machine
Learning
is
a
branch
of
computer
science
that
gives
“computers
the
ability
to
learn
without
being
explicitly
programmed.”
Machine
learning
has
algorithms
that
are
fed
data
and
these
algorithms
analyze
the
data
to
make
predictions
or
recommendations.
Such
algorithms
are
coded
by
humans,
in
ways
that
these
algorithms
cannot
learn.
Machines
only
learn
from
the
data
that
they
receive
and
can
analyze.
In
a
sense,
rather
than
replacing
the
abilities
of
humans
in
the
future,
machines
can
make
it
easier
to
make
complex
computations
fast
enough
to
give
conclusions
that
are
stochastic,
not
deterministic.
Machine
learning
can
do:
●
Recognition
○
Image
recognition
○
Text
recognition
○
Voice
recognition
●
Recommendations
●
Classification
●
Text
to
Speech
●
Predictive
maintenance
Machine
learning
cannot
do:
●
Learning
a
language
from
hearing
verbal
utterances
●
Human
intention
recognition
●
Emotion
recognition●
Gestures
recognition
●
Interact
with
and
understand
humans
Usually,
machine
learning
algorithms
require
large
amounts
of
data
to
be
trained
enough
before
they
begin
to
give
useful
results.
Machine
learning
is
not
and
will
not
be
able
to
replace
humans
explicitly.Artificial
Intelligence
project
life
cycle
A
project
lifecycle
describes
the
phases
through
which
a
project
progresses.
This
sequence
of
the
phases
and
their
dependency
is
also
clearly
mentioned.
AI
project
life
cycle
mainly
has
5
stages.
These
stages
define
the
start
to
end
of
the
development
of
AI-powered
solutions
in
specific
and
clear
steps:
The
5
stages
of
the
AI
Project
Life
Cycle
are:
●
Problem
scoping
●
Data
acquisition
●
Data
exploration
●
Modeling
●
Evaluation
Figure
1.17
describes
in
sequence
the
various
stages
of
an
AI
project
life
cycle:
Phase
1:
Problem
scoping
As
the
name
suggests,
this
initial
phase
of
the
AI
project
lifecycle
is
all
about
understanding
the
problem,
its
scope,
the
boundaries,
identifying
the
problem
statement,
various
factors
which
affect
the
problem
as
well
as
all
parameters
and
aspects
that
define
the
goal
and
the
aim
of
the
project.
This
scoping
can
be
done
by
answering
the
4Ws,
which
are:
Who
:
“Who”
helps
in
identifying
the
stakeholders,
categorizing
all
those
who
are
directly
or
indirectly
impacted
by
the
problem.
What
:
“What”
helps
in
understanding
and
identifying
the
nature
of
the
problem
while
also
collecting
evidence
to
prove
that
the
problem
exists.
Where
:
“Where”
helps
in
identifying
the
roots
of
the
problem,
where
it
arises,
the
situation,
and
the
location
it
arises.
Why
:
“Why”
helps
with
why
the
problem
is
worth
solving.
Phase
2:
Data
acquisition
Data
acquisition
is
the
process
of
collecting
accurate
and
reliable
data
that
cumulatively
cover
variables
and
attributes
of
the
problem
statement
in
its
entirety.
Data
can
be
in
the
format
of
text,
video,
images,
audio,
and
so
on
and
it
can
be
collected
from
various
sources
like
interest,
journals,
newspapers,
and
so
on.
That
is
data
can
be
structured
or
unstructured
or
in
any
non-specific
form.
Data
can
be
collected
from
various
sources:
●
Databases
●
Web
pages
●
Devices
like
cameras
and
sensors
(e.g.
in
Autopilots,
weather
predictions)
●
Public
surveys
/records
of
purchases,
transactions,
registrations,
and
more
Phase
3:
Data
explorationData
exploration
is
the
process
of
performing
operations
like
data
cleaning,
finding
missing
values,
removing
useless
data,
and
basic
statistical
analysis
for
arranging
the
data,
gathered
as
in
phase
2,
uniformly
and
meaningfully.
Data
can
be
arranged
in
the
form
of
a
table,
plotting
a
chart,
or
making
a
database.
Multiple
visualization
tools
are
available
in
the
market
for
offering
data
in
visibly
grasping
formats.
A
few
of
the
tools
to
use
for
data
exploration
are:
●
Google
charts
●
Fusion
charts
●
Tableau
●
High
charts
Phase
4:
Modeling
Modeling
is
the
phase
of
the
AI
project
lifecycle
in
which
different
models
based
on
the
visualized
data
can
be
created
and
developed.
Models
help
in
formulating
mathematical
relations
between
data
and
the
outcome.
These
models
can
also
be
checked
for
their
advantages
and
disadvantages
Refer
to
Figure
1.18:
While
we
have
covered
learning-based
models
in
previous
sections,
a
rule-based
model
is
where
the
relationship
or
patterns
in
data
are
defined
by
the
developer.
The
machine
performs
tasks
according
to
the
information
and
these
rules
as
given
by
the
developer.
As
an
example,
for
rule-based
learning,
a
bank
grants
a
loan
to
a
customer
based
on
certain
rules
that
measure
the
personal
and
financial
information
against
a
set
of
levels
that
help
decide
if
a
loan
is
to
be
granted.
Phase
5:
Evaluation
Evaluation
is
the
last
phase
in
the
AI
Project
lifecycle.
Here
the
model
developed
is
fed
with
input
data
and
the
outcome
is
compared
against
expected
outcomes.
This
stage
determines
the
reliability
of
the
model
and
the
completeness
of
the
data
fed
into
the
model.
Career
opportunities
in
artificial
intelligence
The
Artificial
Intelligence
field
is
vast
to
bring
multiple
career
opportunities.
These
are
primarily
based
on
data,
algorithms
and
machine
learning,
and
application
development.
The
following
table
lists
the
most
common
career
opportunities
in
the
field
of
artificial
intelligence:Conclusion
AI
is
already
a
part
of
our
lives.
With
the
ease
and
automation
it
brings,
AI
is
being
a
focus
area
in
all
fields
of
life,
be
it
healthcare,
manufacturing,
or
performing
routine
daily
tasks.
It
is
going
to
get
evolved
more
and
it
is
not
too
late
to
be
on
board
the
artificial
intelligence
wagon.
In
the
next
chapter,
we
will
be
discussing
key
fields
of
applications
in
AI
and
methodologies
and
their
impact
on
our
society.
At
the
end
of
the
next
chapter,
we
will
be
analyzing
how
we
get
ready
for
the
future
which
will
be
the
AI
age.
