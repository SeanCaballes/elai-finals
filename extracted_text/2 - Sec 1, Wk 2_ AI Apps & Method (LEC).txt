Week
2:
AI
Applications
and
Methodologies
Introduction
In
this
chapter ,
we
will
be
learning
about
the
key
fields
of
application
where
AI
can
be
applied.
These
are
the
applications
that
are
having
an
impact
on
society ,
both
positive
and
negative.
We
will
be
navigating
through
such
applications
we
all
may
have
used
at
some
point
in
time
or
have
become
part
of
our
daily
lives.
We
will
also
learn
about
the
machine-learning
techniques
behind
these
applications.
These
applications
have
the
capacity
to
bring
about
global
societal
changes.
It
is
therefore
very
necessary
to
get
ready
for
the
future,
the
AI
age.
Key
fields
of
application
in
AI
In
this
section,
we
will
be
discussing
applications
like
chatbots,
text-based
voice
assistants,
computer
vision,
autonomous
systems
like
self-driving
cars
and
others
that
are
inherently
using
AI
technologies.
Chatbots
(Natural
Language
Processing,
speech)
Chatbots
are
very
common
text-based
applications
used
in
various
ways
to
reach
out
and
interact
with
people.
Let
us
take
an
understanding
of
chatbots
and
the
technology
they
are
based
on.
What
are
chatbots
As
the
name
implies,
a
“Chatbot”
is
a
conversational
robot.
AI
powered
Chatbots
can
grasp
and
understand
natural
languages
or
multiple
human
languages
like
English,
Dutch,
Hindi,
French,
German,
and
so
on.
These
chatbots
can,
therefore,
respond
to
people
online
using
the
“live
chat”
feature
on
webpages
or
portals,
or
applications.
AI
powered
chatbots
have
the
ability
to
mimic
human-like
conversations
without
the
need
for
any
human
intervention
at
their
end,
enacting
a
real-life
agent.These
chatbots
are
based
on
machine
learning
and
build
a
database
of
answers,
eventually
pulling
the
relevant
info
before
pushing
it
to
the
user
at
the
other
end.
Chatbot
systems
can
communicate
via
written
or
voice
messages.
The
talking
robots
are
usually
termed
“voice
bots”.
Benefits
of
chatbots
The
chatbots
are
used
to
provide
customer
support,
answer
inquiries,
issue
tracking,
or
any
other
contextual
support
enhancing
customer
engagement
and
satisfaction.
These
chatbots
can
be
replicated
across
industry
verticles
integrated
with
various
informational,
customer ,
and
business
offerings
centric
databases.
Since
these
chatbots
are
automated,
it
provides
immense
value
to
both
the
users
and
the
organizations/businesses
hosting
them.
The
following
Figure
2.1
illustrates
some
benefits
of
chatbots
in
organizations:
●
24x7
availability
:
A
chatbot
is
available
along
with
the
portal/application
where
it
is
hosted,
enabling
organizations
to
reach
out
to
intended
users
all
the
time.
●
Availability
on
digital
platforms:
Chatbots
can
be
accessed
via
digital
devices
from
anywhere
at
any
hour ,
again
easing
out
organizations
on
complete
human
dependency
at
odd
hours.
●
Saves
Times:
These
chatbots
help
in
saving
time
by
providing
prompt
replies
to
the
users,
thus
catering
to
multiple
of
them
in
parallel.
●
Ease
of
Users’
data
collection:
The
Organization
gathers
meaningful
huge
customer
data
sets
in
less
time.
This
data
helps.
●
Ease
of
lead
generation:
Based
on
customer
likes
and
inclinations,
chatbots
intelligently
recommend
products
that
help
increase
lead
generation
(identifying
and
cultivating
potential
customers
for
products
or
services
offerings.).
●
Enhanced
customer
engagement:
The
ease
of
use
of
chatbots,
prompt
support,
consistent
replies,
personalized
experience,
and
most
of
the
previously
mentioned
benefits
allows
the
customer
to
seek
more
info
and
be
ready
to
provide
feedback.
This
enhanced
customer
engagement
can
benefit
any
organization
in
achieving
the
intended
purpose
of
these
chatbots.
●
Provides
integrated
support:
Chatbots
pull
answers
from
databases
which
could
be
product/service
offerings,
customer
info,
ticket
status,
and
so
on.
The
customer ,
thereby ,
gets
one
channel
for
all
info
that
is
sought.
●
Industry
agnostic:
The
chatbots
can
be
deployed
across
industries
as
all
it
needs
is
the
right
set
of
data
to
pull
info
from.
●
Measurable
performance:
The
chatbots
can
be
upgraded
as
the
performance
is
measurable.
●
Contextual
support
to
customers:
With
access
to
databases,
chatbots
can
provide
customers
with
accurate
answers
and
information
as
desired.
The
following
Figure
2.2
illustrates
some
benefits
of
Chatbots
to
users/customers:
●
24x7
availability:
Ease
of
Access
on
digital
devices
from
portals
and
apps
that
are
always
ON.
●
Multi-lingual
support:
Current
chatbots
are
designed
to
provide
multi-
lingual
support,
enhancing
customer
support
by
removing
language
barriers
irrespective
of
the
region
the
customer
is
based
in.
●
Saves
time:
With
prompt
and
accurate
responses
and
consistency
in
answers,
customer
time
is
saved
considerably ,
and
the
customer
is
prompted
to
seek
more
info
and
provide
valuable
feedback.
●
Consistent
answers:
Receiving
consistency
in
replies
to
their
queries
on
chatbots
is
an
added
benefit
to
the
customer
experience
while
using
chatbots.
●
Personalized
experience:
By
pulling
data
from
various
sources
and
having
access
to
the
customer
profile,
chatbots
are
capable
of
providing
a
personalized
experience
to
the
users.
●
Prompt
responses:
Getting
immediate
responses
with
next
to
no
waiting
period
or
being
put
on
hold
saves
time
for
the
users.
●
Integrated
and
contextual
support:
Having
access
to
data,
chatbots
can
provide
accurate
and
personalized
answers
to
complex
user
queries.
Chatbots
in
key
industries
Chatbots
can
benefit
various
industries
irrespective
of
the
business.
Chatbots
can
provide
support
in,
but
not
limited
to,
marketing,
sales,
customer
support,
or
IT
service
helpdesk.
These
can
also
be
used
for
scheduling
appointments,
reviews,
feedback,
and
much
more.
Let’s
have
a
look
at
a
handful
of
key
industries
where
chatbots
can
revolutionize
user/customer
experience
and
ease
of
doing
business.
Figure
2.3
lists
these
industries:
●
Human
resources:
Chatbots
can
help
in
the
recruitment
process
right
from
searching
for
candidates
and
evaluating
their
skills
as
per
the
job
description.
●
Retail:
Chatbots
in
retail
or
e-commerce
can
help
answer
customer
queries,
recommend
products
and
services,
place
an
order ,
make
payments,
and
streamline
overall
sales
and
marketing
processes.
●
Healthcare:
Chatbots
can
help
in
scheduling
appointments,
setting
reminders,
recommending
health
checkups,
providing
medical
assistance,
and
more
features
based
on
underlying
algorithms
and
design.
●
Financial
sector:
Chatbots
can
assist
in
making
financial
transactions,
reporting
card
losses
in
banking,
opening
accounts,
answering
customer
queries
related
to
product
offerings
and
services,
recommending
desired
loans,
and
so
on.
●
Education:
Chatbots
can
help
create
a
personalized
learning
environment
for
students.
Students’
responses
can
be
analyzed
to
assist
them
further
with
new
learning
material
or
courses
via
chatbots.
●
Entertainment:
Chatbots
can
help
share
available
movies,
book
tickets,
recommend
movies
based
on
previous
feedback
on
movies
watched,
and
much
more.
●
Service
providers:
Service
providers
like
direct-to-home
(DTH)
can
use
chatbots
to
help
users
navigate
their
portals,
recommend
new
products,
and
help
with
billing
and
technical
customer
support.
●
Travel
and
tourism:
Chatbots
play
a
major
role
in
this
sector .
These
can
provide
weather
information,
and
law
order
situations
and
assist
with
bookings
and
packages
being
offered.
Machine
learning
in
AI-powered
chatbots
AI
powered
chatbots
use
machine
learning
(supervised
or
deep
or
ANN)
to
be
trained
to
provide
human-agent-like
responses
to
the
users.
These
chatbots
use
Natural
language
processing
(NLP),
covered
later
in
the
chapter ,
to
understand
human
language.
Chatbots
based
on
these
advanced
technologies
identify
human
conversation
patterns
and
learn
and
remember
data
efficiently ,
compared
to
human
agents.
Supervised
training
to
test
chatbot
algorithm
These
chatbots
are
trained
using
predefined
responses,
based
on
the
responses
and
the
learnings;
thereby ,
these
chatbots
may
learn
rude
responses
that
can
hamper
brands’
reputations.
For
example,
the
chatbots
may
pick
up
racist,
sexist,
or
abusive
remarks.
This
possibility
of
providing
incorrect
answers
raises
the
need
for
human
operators
to
rectify
the
mistakes.
These
may
need
to
be
upgraded
for
consistency
in
answers
in
the
future.
Human-in-the-loop
(HITL)
becomes
necessary
to
regularly
update
and
train
the
chatbot.The
role
of
human
agents
then
becomes
overlooking
chatbots’
conversations
and
answering
the
question
that
chatbots
are
unable
to
handle.
There
is
regular
updating
of
the
algorithms
of
this
chatbot
as
well
as
training
of
these
chatbots.
Generative
chatbots
–
Deep
learning
Generative
chatbots
are
based
on
deep
learning.
These
advanced
chatbots
can
answer
complex
queries
of
users.
Deep
learning
technology
allows
chatbots
to
understand
users’
questions
with
the
help
of
neural
networks,
at
times
from
famous
movies
and
books.
Such
chatbots
get
smarter
with
every
conversation
and
can
imitate
real
people.
These
chatbots
can
also
act
like
voice
bots
by
their
ability
to
understand
voice
commands
and
recognize
speech.
Artificial
neural
networks
to
replicate
a
human
brain
–
Intelligent
chatbot
Intelligent
chatbots
based
on
Artificial
neural
networks
can
replicate
human
brains.
It
can
easily
learn
the
new
intent
of
the
customer
and
engage
in
meaningful
conversations
with
the
users/customers.
Natural
Language
Processing
(NLP)
–
Natural
conversation
Natural
language
processing
is
one
subset
of
Artificial
Intelligence
technology
that
enables
computer
programs
to
process
or
understand
human
language
–
both
written
and
spoken
in
the
same
ways
as
humans
do.
NLP
combines
computational
linguistics
(that
is,
analysis
and
synthesis
of
language
and
speech
by
applying
computer
science
techniques)
with
statistical,
machine
learning,
and
deep
learning
models.
NLP
can
help
computer
programs
translate
text
from
one
language
to
another.
As
such
NLP
in
Artificial
Intelligence
technology
helps
chatbots
to
converse
like
a
human.
Chatbots
based
on
NLP
can
easily
understand
users’
intent
and
their
purchasing
intent.Natural
language
understanding
(NLU)
–
Complex
questions
Chatbots
process
the
input
information
as
human
text
or
speech
through
NLP
and
understand
these
human
interactions
through
NLU.
NLU
enables
computer
programs
to
communicate
back
to
humans
in
their
own
languages.
As
such,
after
processing
the
human
conversation
through
NLP,
Natural
language
understanding
is
used
to
understand
the
structure
of
the
conversation
and
converse
with
the
customers.
To
interpret
human
texts
for
speech,
NLU
breaks
complex
sentences
into
simpler
ones.
NLU
uses
algorithms
to
reduce
human
speech
or
text
into
a
structured
ontology
--
a
data
model
consisting
of
semantics
and
pragmatics
definitions.
Recognition
–
both
intent
and
entity
–
are
two
fundamental
concepts
of
NLU.
Intent
recognition
is
the
first
and
most
important
part
of
NLU.
This
process
is
used
to
identify
the
user's
sentiment
in
input
text
or
speech
and
determine
their
objective.
This
helps
establish
the
meaning
of
the
input.
Entity
recognition,
as
the
name
suggests,
is
a
specific
type
of
NLU
that
focuses
on
identifying
the
entities
in
the
input.
It
then
extracts
important
information
about
those
entities.
The
entities
are
of
two
types:
named
and
numeric.
Named
entities
can
be
categorized
such
as
people,
companies,
and
locations.
Numeric
entities
can
be
numbers,
currencies,
and
percentages.
Voice
assistants
(Alexa,
Siri,
and
others)
Voice
assistants
or
digital
assistants
or
virtual
assistants,
or
AI
assistants
are
software
programs
that
carry
out
tasks
via
voice
commands
as
input.
Voice
assistants
are
based
on
AI
and
ML
technologies
that
help
recognize
voice
inputs,
and
convert
voice
to
digital
data
efficiently
for
software
to
analyze
and
perform
desired
tasks
in
accordance.
Benefits
Voice
assistants
are
used
to
accomplishing
everyday
tasks.
Say,
for
example,
they
can
answer
queries,
integrate
with
smart
homes
to
turn
on
and
off
lights
and
electrical
appliances,
and
more.
These
voice-activated
assistants
come
preinstalled
on
smartphones.
Voice-activated
speakers
are
becoming
common
platforms
in
homes
and
workplaces.Having
these
assistants
can
be
a
great
help
to
perform
tasks
on
a
mere
voice
command,
as
seen
in
the
following
scenarios:
●
Stay
updated
about
current
and
trending:
At
a
voice
command,
get
all
kinds
of
information
available
on
the
Internet,
as
well
as
seek
info
about
the
weather ,
current
affairs,
news,
traffic,
and
more.
●
Music:
Command
voice
assistants
to
play
music
matching
certain
moods
or
command
a
playing
a
particular
song.
●
Devices’
control:
Control
electrical
and
electronic
devices
and
other
smart
appliances
by
voice
commands
like
“switch
on
the
geyser”,
“switch
off
lights”,
and
“set
AC
temperature”.
●
Banking
assistance:
Voice
assistants
can
help
check
balances,
order
banking
products,
and
get
transaction
details
for
those
banks
that
allow
access
to
such
services
via
AI
assistance.
●
Organize
the
day:
Voice
assistants
can
be
used
to
set
reminders
for
the
day’s
schedule
by
accessing
the
calendar .
●
Support
for
differently
abled
or
dependent
folks:
Voice
commands
to
operate
devices,
and
voice
search
function
support
visually-impaired,
elderly ,
and
dependent
persons
in
their
routine
reducing
the
dependency
on
human
intervention.
Pitfalls
Every
technology
has
two
sides.
With
the
ease
voice
assistants
bring
to
perform
our
routine
tasks,
they
also
do
have
a
few
downsides:
●
Privacy
at
stake:
With
the
machine
learning
methodologies
at
their
backend,
these
voice
assistants
are
continuously
taking
voice
inputs
and
learning.
Hence,
they
learn
a
lot
more
than
desired.
●
Sharing
personal
data:
Voice
commands
for
performing
various
tasks
cannot
be
achieved
without
giving
access
to
personal
data
to
these
voice
assistants,
which
can
be
challenging
in
case
these
assistants
are
hacked
into.
In
case
smart
homes
are
hacked
into,
imagine
the
damage
it
can
cause
with
personal
data
being
exposed.
●
Familiarity
with
lifestyle:
Voice
assistants
do
learn
the
arrival
timings,
the
day’s
schedule,
and
calls
made
along
with
bank
details
(if
provided
access).
They
also
record
habits
like
preferred
room
temperature,
songs,
usual
moods,
and
much
more.
In
some
cases,
it
may
also
record
food
and
shopping
preferences.
●
Identity
theft:
With
all
the
personal
data
recorded,
if
any
hacker
is
able
to
hack
this
voice
assistance,
it
will
be
more
like
an
identity
theft
than
a
mere
financial
or
trespassing
hit.Examples
Voice
assistant
systems
can
be
found
preinstalled
on
smart
speakers,
smartwatches,
mobile
phones,
tablets,
and
other
digital
devices.
A
few
of
the
known
names
in
households
are:
●
Alexa
(Amazon)
●
Siri
(Apple)
●
Google
Assistant
(Google)
●
Bixby
(Samsung)
●
Cortana
(Microsoft)
Computer
vision
As
the
name
suggests,
computer
vision
may
be
considered
the
ability
of
a
computer
to
see.
Computer
vision
is
based
on
artificial
intelligence
(AI)
technology
and
gives
computer
systems
the
ability
to
obtain
meaningful
data
from
visual
inputs
such
as
photos
and
videos.
Again,
like
other
AI-based
systems,
the
insights
gained
from
computer
vision
are
used
to
perform
desirable
automated
actions.
Currently ,
deep
learning
techniques
are
commonly
used
for
computer
vision.
Computer
vision-based
systems
acquire,
process,
analyze
(based
on
specified
criteria),
and
render
visual
information
thereafter
in
various
formats
such
as
3D
models,
images,
videos,
or
related
volumetric
data.
Weather
predictions
Climate
change
is
increasing
the
intensity
and
frequency
of
extreme
weather
events
that
are
being
recorded
across
the
globe.
Older
weather
forecasting
systems
relied
on
supercomputers
needed
to
process
large
amounts
of
data
gathered
from
across
the
globe
such
as
temperature,
pressure,
humidity ,
and
wind
speed.
This
came
with
the
need
to
create
a
computationally
efficient
model,
capable
of
accurately
predicting
upcoming
weather .
Scientists
called
such
a
system
Deep
Learning
Weather
Prediction
(DLWP)
.
The
DLWP
is
based
on
an
AI
algorithm.
The
system
learns
and
recognizes
patterns
in
historical
weather
data
based
on
global
grids.AI-Powered
weather
forecasting
systems
can
help
identify
accurately
potential
extreme
weather
2–6
weeks
into
the
future
or
in
months.
Extreme
weather
prediction
is
made
accurately
and
well
in
advance,
giving
communities
and
critical
sectors
such
as
public
health,
water
management,
energy ,
and
agriculture
to
mitigate
potential
disasters.
Price
forecast
for
commodities
Commodities
play
a
crucial
role
in
the
global
economy
and
are
one
of
the
major
motivators
of
inflation
and
economic
activities.
A
significant
percentage
of
the
market
is
composed
of
just
the
oil
industry
and
natural
gas
industries.
Other
significant
contributors
include
metal,
mineral,
and
agricultural
commodities.
Price
forecast
for
commodities
refers
to
the
process
of
making
forecasts
against
products’
prices
based
on
previous
and
present
data
or
trends
analysis.
AI-based
systems
can
help
mitigate
risks
of
investment
and
returns
thereby .
These
systems
can
be
fed
with
data
pertaining
to
historical
price
trends,
factors
that
drive
the
prices,
volatility
in
price
variation,
and
the
impact
of
various
seasons.
AI-based
price
forecasting
systems
thus
eliminate
human
emotions
and
gut
feelings
in
their
predictions.
Based
on
the
commodity
or
service,
price
prediction
AI-powered
systems
use
algorithms
to
analyze
it
based
on
the
characteristics,
demand,
and
market
trends.
The
system
then
sets
a
price
it
predicts
that
attracts
customers
and
maximizes
sales.
Self-driving
cars
One
of
the
characteristics
of
AI-based
autonomous
systems
is
that
they
function
on
their
own
while
adapting
and
responding
to
dynamic
environments
and
changing
situations.
A
common
application
of
autonomous
computer
systems
is
in
the
transportation
industry ,
especially ,
consumer
vehicles
that
use
automated
and
assistive
technology
but
are
not
fully
autonomous
in
nature
as
of
date.
Where
autonomous
is
defined
as
“having
the
freedom
to
govern
itself
or
control
its
own
actions”
A
self-driving
car,
also
known
as
a
driverless
car,
or
robotic
car
incorporates
vehicular
automation
AI-powered
systems.
In
a
sense,
a
self-driving
car
is
capable
of
sensing
its
environment
and
moves
safely
with
little
or
no
human
intervention.
The
surroundings
are
perceived
using
a
set
of
sensors
like:
●
Thermographic
cameras:
A
thermographic
camera
is
a
device
that
creates
an
image
using
infrared
(IR)
radiation●
Radar:
Radar
sensors
transform
microwave
echo
signals
into
electrical
signals.
They
detect
motion
by
perceiving
an
object’ s
position,
shape,
motion
characteristics,
and
motion
trajectory
using
wireless
sensing
technology .
●
LiDAR:
Light
Detection
and
Ranging
(LiDAR)
sensors
in
autonomous
vehicles
provide
a
high-resolution
3D
view
of
the
surroundings.
●
Sonar:
Sonar
or
an
ultrasonic
sensor
is
an
electronic
device
that
measures
the
distance
of
a
target
object
by
emitting
ultrasonic
sound
waves.
The
reflected
sound
is
then
converted
into
an
electrical
signal.
●
GPS:
Global
positioning
system
sensors
use
a
satellite-based
navigation
system
in
orbit
around
the
earth
to
provide
position,
velocity ,
and
timing
information.
●
Odometry:
Odometry
is
the
use
of
data
from
motion
sensors
to
estimate
the
change
in
position
over
time,
relative
to
an
earlier
known
position.
●
Inertial
sensors:
An
inertial
sensor
is
used
to
gather
the
acceleration
and
angular
velocity
of
an
object.
The
environment
for
a
self-driving
car
includes
obstacles,
paths,
relevant
traffic
signals,
signages,
speed
limits,
traffic
diversion,
other
vehicles,
distance
from
moving
objects,
and
much
more.
Artificial
intelligence-powered
control
systems
are
deployed
in
these
robot-
cars
that
learn
all
the
gathered
sensory
information
in
order
to
control
the
vehicle
and
support
various
autonomous-driving
tasks
and
operations.
As
a
key
future
technology ,
AI-powered
self-driving
cars
are
predicted
to
have
a
comprehensive
impact
on
various
industries
including,
but
not
limited
to,
automobile,
health,
welfare,
urban
planning,
traffic,
insurance,
services,
and
much
more.
Connected,
Autonomous,
Shared,
and
Electric
(CASE)
Mobility
is
a
future
mobility
vision
based
on
self-driving
cars
combined
with
other
emerging
automotive
technologies
such
as
electric
vehicles,
connected
vehicles,
and
shared
mobility .
SAE
International,
formerly
named
the
Society
of
Automotive
Engineers
,
is
a
United
States-based,
globally
active
professional
association
and
standards-developing
organization
for
engineering
professionals
in
various
industries
(as
per
Wikipedia).
SAE
International
has
developed
a
framework
that
categorizes
different
levels
of
autonomy
in
vehicles.
The
levels
in
the
framework
are
not
fixed,
for
instance,
some
break
their
hierarchy
into
five
layers
and
some
into
six.
The
distinctions
between
various
levels
are
also
not
firm
and
some
algorithms
may
exhibit
behavior
from
two
or
three
levels
at
the
same
time.
These
levels
can
be
described
as:●
Level
0:
No
automation;
the
human
does
all
operations
except
some
automatic
systems
like
windshield
wipers
or
heating.
●
Level
1:
Hands-on/shared
control;
some
operations
like
braking
or
lane
following
are
delegated
to
the
car.
●
Level
2:
Hands
off;
The
car
does
all
major
operations
like
braking,
acceleration,
or
lane
following;
however ,
the
human
must
remain
alert
to
take
control
at
all
times,
maybe
by
also
having
to
have
hands
on
the
steering
wheel
all
the
time.
●
Level
3:
Eyes
off;
The
human
may
not
remain
alert
all
the
time
and
may
occasionally
turn
attention
away
from
the
road
for
a
short
amount
of
time,
however ,
must
be
ready
to
respond
to
an
alarm
in
case
needed.The
car
is
in
self-control
over
mapped
routes
but
not
on
paths
that
are
new
and
not
mapped
in
advance.
●
Level
4:
Mind
off,
this
level
may
require
humans
to
take
control
in
cases
where
the
paths
aren’t
well
understood
by
the
AI.
●
Level
5:
Steering
wheel
optional.
This
level
is
more
like
a
cab
service
that
humans
need
not
control.
Well-known
automobile
companies
that
have
implemented
predictive
analytics
in
their
autonomous
vehicles
are:
●
Tesla
●
Ford
●
Volkswagen
Characteristics
and
types
of
AI
AI
is
a
technology
that
enables
systems
to
develop
cognitive
skills
and
think
and
behave
like
humans.
The
main
components
of
AI
are:
●
Feature
engineering:
This
primarily
means
the
feature
extraction
process
of
identifying
a
nominal
set
of
attributes
from
given
data
sets.
●
Artificial
Neural
Networks
●
Deep
Learning
Other
characteristics
that
utilize
the
maximum
efficiency
of
this
technology
are:
●
Natural
Language
Processing
●
Intelligent
Robotics:
Robotics
is
the
amalgamation
of
engineering,
science,
and
technology
that
produces
programmable
machines
known
as
robots
that
canmimic
human
actions
or
assist
humans.
AI
powered
robots
are
systems
that
can
learn
and
adapt
to
perform
independently
without
human
intervention.
●
Perception:
Take
inputs
from
sensors
and
process
the
collected
data
to
give
the
desired
output.
Applications
based
on
these
processes
are
facial
recognition,
computer
vision,
and
much
more.
●
Automate
Simple
and
Repetitive
tasks
:
As
the
heading
suggests,
this
is
for
performing
monotonous
and
repetitive
tasks
that
may
involve
large
data
sets
as
input
or
voice
assistant
systems
performing
daily
routine
tasks.
●
Data
Ingestion:
The
process
of
saving
unstructured
data
extracted
from
various
sources
to
a
huge
database
medium
for
accessing,
analyzing,
and
preparing
AI
models.
●
Imitation
of
Human
Cognition:
An
example
of
such
capabilities
is
Chatbots
that
can
imitate
human-like
conversations
by
intent
and
entity
recognition.
●
Quantum
computing:
AI
has
helped
by
solving
complex
quantum
physics.
Quantum
computing
focuses
on
developing
complex
algorithms
of
quantum
for
revolutionizing
and
advancing
computational
tasks.
●
Cloud
computing:
Introducing
AI
capabilities
in
cloud
computing
can
assist
organizations
in
addressing
the
never-ending
growing
data
ingested
in
their
data
centers
and
systems.
●
Ethical
gene
editing:
AI
has
the
potential
to
contribute
successfully
in
the
medical
field,
especially
in
the
treatment
of
common
complex
diseases
or
disorders
caused
by
gene
mutations.
●
Intelligent
disaster
response:
With
advancements
in
technology ,
Modern
rescue
systems
utilize
sensor-based
systems,
unmanned
aerial
vehicles,
or
AI-powered
robots
to
collect
accurate
information
about
the
location
of
victims
or
extent
of
damage,
or
a
forecast
of
upcoming
disasters.
Data-driven
Consumer-centric
businesses
are
usually
driven
by
data-capturing
customer
profiles,
likes,
dislikes,
purchasing
power ,
frequency
of
purchases,
and
unending
lists
that
can
help
improve
offerings
and
revenue
growth.
Next-generation
data-driven
AI
is
a
game
changer
for
such
businesses.
Let
us
analyze
the
most
common
of
the
customer-centric
businesses
we
come
across
on
a
day-to-day
basis.
●
Groceries:
Forecast
customer
needs
and
ensure
product
availability
based
on
location
and
purchasing
preferences.●
Restaurant:
Analyze
customer
footfall
and
stock
up
on
resources
accordingly .
Also,
analyze
preferred
dishes
during
the
time
of
the
year
minimizing
wastage
and
achieving
customer
satisfaction
too.
●
Hotel:
Analyze
footfall
in
various
seasons
and
plan
the
resources
accordingly .
The
data
can
also
help
offer
optimal
pricing
and
offer
relevant
packages
to
maintain
business
throughout
the
year .
●
Retail:
Analyze
discounts
to
be
offered
in
various
seasons
that
cause
a
positive
impact
on
sales.
Ensure
the
demand
and
supply
are
well
balanced
and
also
identify
cross-selling
opportunities.
●
E-commerce:
Analyze
procurement
trends
like
items
bought
together
and
build
pricing
models.
Forecast
product
sales
depending
on
its
pricing
and
features
and
targeted
customers
based
on
similar
products.
Autonomous
systems
Current
AI-powered
systems
are
automated
but
not
entirely
autonomous.
Autonomous
artificial
intelligence
systems
will
be
a
reality
when
robots,
cars,
planes,
and
other
devices
are
able
to
execute
extended
sequences
of
operations
without
guidance
and
intervention
from
humans.
To
achieve
and
build
autonomous
systems,
researchers
are
continually
refining
their
algorithms
and
also
their
approach.
To
have
a
better
understanding,
the
entire
job
is
divided
into
layers
as
mentioned
follows:
●
Sensing:
Incorporate
sensors
that
collect
all
possible
data
that
can
impact
the
outcome.
We
had
seen
the
sensors
used
in
self-driving
cars
earlier
in
the
chapter .
●
Fusion:
The
collected
data
must
be
holistically
analyzed
to
get
a
complete
view
of
the
ecosystem
so
as
to
build
a
model
that
enables
the
system
to
take
the
most
accurate
or
human-like
decisions
independently .
●
Perception:
After
the
model
is
constructed,
the
system
must
be
able
to
identify
and
perceive
the
ecosystem
completely .
●
Planning:
Having
perceived
the
environment,
the
next
expected
step
is
to
plan
the
best
possible
action
to
be
taken.
●
Control:
The
action
must
be
executed
in
a
controlled
manner
and
independently
Recommender
systems
As
the
name
suggests,
a
recommender
system
or
a
recommendation
system
provides
suggestions
or
/
recommends
items
most
relevant
or
applicable
to
a
particular
user .The
suggested
items
could
refer
to
products,
services
or
even
music
to
be
played,
or
news
to
be
heard.
These
systems
are
best
used
when
the
list
available
to
choose
from
is
huge
and
overwhelming.
Recommender
systems
help
in
decision–making
processes.
Human-like
Scientists
and
engineers
continue
to
push
the
boundaries
of
what
can
be
achieved
with
AI.
But
we
are
short
of
the
machines
that
we
witness
in
sci-fi
movies.
Current
systems
do
not
understand
how
the
world
works.
AI
research
scientists
are
still
figuring
out
how
to
make
the
paradigm
shift
from
data-driven
to
more
intuitive
human-like
thinking
systems
displaying
cognitive
skills.
However ,
these
machines
will
be
learning
from
watching
humans
achieve
human-like
capabilities.
Things
to
ponder:
We
have
subtle
gender
bias
displayed
by
humans
in
almost
all
walks
of
life
and
even
at-home
setups.
Will
the
AI-powered
human
systems
pick
up
the
same
learning
and
behavior?
These
are
abstract
behavioral
aspects
that
cannot
be
programmed
as
right
or
wrong
via
data
sets.
Cognitive
computing
Cognitive
computing
is
an
attempt
to
have
computers
imitate
the
working
of
a
human
brain.
Cognitive
computing
refers
to
the
use
of
artificial
intelligence
and
underlying
technologies
like
language
processing,
and
machine
learning
to
the
top
with
human
capabilities
that
help
regular
computing
better
solve
problems
and
analyze
data
to
tackle
complex
decision-making
processes.
The
characteristics
of
cognitive
computing
are:
●
Perception:
Five
senses:
sight,
taste,
smell,
sound,
and
touch
contribute
towards
forming
a
human
perception.
Perceptions
are
a
cognitive
process
as
we
often
consciously
and
unconsciously
process
information
gained
through
our
senses,
forming
thoughts,
and
opinions
and
giving
emotional
reactions.
●
Learning:
Learning
can
be
achieved
through
many
cognitive
processes,
such
as
memory ,
thought,
and
perception.
To
learn
quickly
and
retain
information,
multiple
processes
need
to
be
combined.
For
example,
reading,
writing,
listening,
verbal
communication,
and
thinking
can
help
learn
things
faster .●
Reasoning:
It
is
the
ability
to
analyze
and
perceive
any
given
information
from
various
perspectives
by
breaking
it
down
and
structuring
it
in
a
logical
order .
Deep-dive
into
NLP,
CV,
and
much
more
Computer
machines
understand
bits,
which
could
take
a
value
of
zero
or
one.
Natural
Language
Processing
(NLP)
comes
in
handy
as
a
processing
tool
for
computers
to
understand
input
words,
languages,
and
sentences.
NLP
includes
various
language
preprocessing
techniques.
These
include
the
following
techniques:
●
Tokenization:
Involves
breaking
down
sentences
into
smaller
units,
that
is,
words.
●
Stemming:
Involves
extracting
the
core
context
from
words
by
cutting
the
suffixes
of
words.
For
example,
worries
→
worri.
●
Lemmatization:
Similar
to
stemming
but
involves
reducing
the
word
to
its
root.
For
example,
worries
→
worry .
●
Bag
of
Words:
Involves
representing
the
significant
words
in
the
collection
in
the
form
of
vectors.
●
TF-IDF:
This
is
similar
to
a
bag
of
words
and
adds
higher
weightage
to
significant
words
and
vice
versa.
The
output
of
the
above
techniques
is
prepared
data
which
is
then
passed
on
to
complex
models
to
generate
meaningful
outputs
such
as
sentiment
analysis,
word
prediction
or
fully
conversing
chatbots.
While
NLP
deals
with
textual
data,
Computer
Vision
(CV)
involves
processing
images
by
computer
and
extracting
useful
information
or
performing
meaningful
tasks
on
those
images.
A
computer
views
images
as
pixels
and
channels
(red,
green,
blue).
The
combinations
of
these
channels
form
the
basis
of
Computer
Vision.
Few
of
the
Computer
Vision
techniques
as
mentioned
as
follows:
●
Edge
detection:
Detecting
objects’
edges
in
the
image.
●
Color
segmentation:
create
a
mask
for
the
image
by
grouping
similar
pixels
together .
●
Noise
filtering:
This
involves
making
the
image
clearer
by
removing
unwanted
entities.
●
Adding
filters:
This
involves
changing
colors,
cropping
and
adding
blurs,
to
the
image,
and
more.
Examples
of
real-world
applications
based
on
NLP
and
CV
are
as
follows:●
Siri,
Alexa,
and
other
voice
assistants
use
NLP
●
Google
search
by
voice
is
based
on
NLP
●
Real
time
filters
in
Snapchat
are
based
on
CV
AI
and
society
Our
society
can
be
categorized
into
people
who
use
AI
and
are
aware,
who
use
AI
and
are
not
aware,
people
who
are
impacted
by
AI
as
part
of
a
community
or
group,
and
people
who
are
not
impacted
by
AI
systems.
These
four
categories
can
be
disjoint
sets
or
have
a
common
data
set.
Let
us
have
a
look
at
a
few
of
the
AI
applications
that
are
top
AI
trends
across
the
world:
Computer
vision
We
are
using
AI-powered
computer
vision
(capturing
and
interpreting
information
from
images
and
video
data)
while
unlocking
smartphones.
Here
by
applying
ML
models,
analyze
various
features
of
the
face,
such
as
the
placement
of
eyes
and
nose,
images,
and
combine
them
all
into
a
unique
code
to
match
against
the
face
stored.
Chances
of
a
random
person
unlocking
are
as
rare
as
one
in
a
million.
Autonomous
vehicle
industry
Self-driving
vehicles
are
going
to
be
the
future.
With
their
inbuilt
AI-powered
technologies
and
the
right
set
of
hardware,
these
would
reduce
the
fatality
rates
over
time
as
compared
to
human-driven
vehicles.
Tesla,
an
American
multinational
automotive
company ,
designs
and
develops
electric
vehicles.
Based
on
advanced
AI
for
vision
and
planning,
Tesla
plans
to
achieve
full
self-driving
cars
and
beyond.
Their
current
autopilot
feature
requires
active
supervision
by
a
human.
That
means
their
vehicles
are
not
yet
autonomous.
Refer
to
their
page
https://www .tesla.com/autopilot
.
Other
automotive
companies
engaged
in
developing
autonomous
vehicles
are:
●
Flux
Auto
(
https://fluxauto.xyz/
)
-
Self-driving
trucks.
●
Minus
Zero
(
https://minuszero.in
)
–
India’ s
first
self-driving
vehicles
prototypes.●
Ati
Motors
(
https://atimotors.com/
)
–
automate
trolley
and
bin
movements.
●
Swaayatt
Motors
(
http://www .swaayatt-robots.com/
)
-
developing
level-5
autonomous
driving
technology .
●
AutoNxt
Automation
Pvt
Ltd
(
https://www .autonxt.in/
)
–
Electric
Autonomous
tractors.
Chatbots
and
virtual
assistants
Chatbots
have
proved
to
be
a
success
as
virtual
assistants.
Let
us
consider
examples:
●
Indigo
airlines
chatbot
(
https://www .goindigo.in/support.html
).
Their
chat
assistant,
called
Dottie,
is
a
conversational
AI-powered
assistant.
It
kind
of
replaces
customer
care
for
help
regarding
commonly
asked
questions
such
as
travel
protocols,
flight
cancellations,
check-ins,
and
so
on.
●
Valyant
AI
(
https://valyant.ai/
):
conversational
AI
platform
for
the
Quick
Serve
Restaurant
(QSR)
industry .
Language
modeling
Language
Modeling
(LM)
is
a
fundamental
task
in
natural
language
processing.
Language
modeling
in
NLP
can
be
based
on
statistical
models
or
neural
language
models.
Top
Language
Models
examples
are:
●
Speech
recognition:
Voice
assistants
such
as
Siri,
Alexa,
Google
Homes,
and
more.
●
Machine
Translation:
Google
Translator
and
Microsoft
Translate
are
machines
translating
linguistics
units
into
various
languages.
●
Parsing
tools:
That
enable
spell
check
and
apply
grammar
rules
and
syntax.
●
Information
retrieval:
Google
search
engine
is
used
for
searching
information.
Other
areas
where
AI-powered
applications
are
very
common
are:
●
Online
shopping:
personalized
recommendations
provided
to
users
based
on
certain
parameters.
Examples
of
companies
providing
AI
technology
for
online
shopping
customer
experience
are:
●
Scalefast
(
https://www .scalefast.com/
)
●
Trendalytics
(
https://www .trendalytics.co/
)
●
Zeta
Global
(
https://zetaglobal.com/
)●
Clairfai
(
https://www .clarifai.com/solutions/ai-in-ecommerce
)
Cybersecurity:
AI
systems
can
help
fight
cyberattacks
based
on
pattern
recognition
and
backtracking
attacks.
A
few
AI-driven
cybersecurity
companies
are:
●
CrowdStrike
(
https://www .crowdstrike.com/
)
●
Darktrace
(
https://darktrace.com/
)
●
Blue
Hexagon
(
https://bluehexagon.ai/
)
●
Cybereason
(
https://www .cybereason.com/
)
●
SparkCognition
(
https://www .sparkcognition.com/
)
●
Tessian
(
https://www .tessian.com/
)
Pandemic
support:
In
the
case
of
Covid-19,
AI
is
being
used
in
identifying
outbreaks
and
categorizing
containment
zones,
tracking
the
spread
of
the
disease,
and
also
in
processing
claims.
●
Researchers
from
DarwinAI
and
VIP
Lab
(University
of
Waterloo)
have
collaborated
to
develop
COVID-Net
-
a
convolutional
neural
network
that
detects
COVID-19
using
chest
radiography .
Refer
to
(https://darwinai.com/case-studies/covid-net-an-open-source-
convolutional-neural-network-for-covid-19-detection-via-chest-
radiography/)
Healthcare
:
AI
in
healthcare
is
used
in
multiple
operations:
●
Administration
:
managing
day-to-day
administrative
tasks,
thereby
minimizing
human
errors
and
maximizing
efficiency .
●
Telemedicine
:
in
non-emergency
situations,
patients
can
reach
out
to
a
hospital’ s
AI
system
to
analyze
if
there
is
a
need
for
medical
attention.
●
Assisted
diagnosis
:
AI-powered
computer
vision
and
convolutional
neural
networks
make
it
possible
to
read
MRI
scans
and
so
on
at
an
exponentially
faster
pace
with
a
considerably
lower
margin
of
error .
●
Additionally ,
it
has
made
its
value
in
Robot-assisted
surgery .
Other
industries
where
AI
is
in
use
are
e-commerce,
human
resources,
customer
service,
and
packaging.
The
future
with
AI
and
AI
in
action
Nations
across
the
globe
are
focusing
on
investing
in
AI
research
centers.
Presenting
the
budget
on
1st
Feb
2023,
India’ s
Finance
Minister ,
NirmalaSitharaman
announced
that
the
central
government
would
create
three
centers
of
excellence
to
boost
Artificial
Intelligence
(AI)
in
India.
The
centers
are
planned
to
be
established
in
top
Indian
institutions
to
ensure
the
realization
of
the
vision
of
'Make
AI
in
India'
and
'Make
AI
work
for
India.'
"Leading
industry
players
will
partner
in
conducting
interdisciplinary
research
and
develop
cutting-edge
applications
and
scalable
problem
solutions
in
the
areas
of
Agriculture,
Health,
and
sustainable
cities,"
Sitharaman
said
in
her
budget
speech.
Figure
2.4
describes
a
few
of
the
industries
that
are
expected
to
witness
advanced
adoption
of
AI
that
will
directly
impact
humans
across
the
globe:
While
the
future
with
AI
is
expected
to
witness
major
developments
across
various
industries
across
the
globe,
leading
to
increased
efficiency
and
productivity
in
various
sectors,
its
deployment
raises
concerns
about
job
displacement
and
the
need
for
reskilling
of
humans.
There
is
also
grave
risk
and
potential
for
AI
to
be
used
for
malicious
purposes.
It
is
essential
to
responsibly
develop
and
govern
AI
to
ensure
its
positive
impact
on
society .
According
to
some
experts,
AI
is
predicted
to
eventually
surpass
human
intelligence.
The
active
contribution
of
AI
in
social
settings
and
the
quality
of
human
lives
will
lead
to
debates
around
ethics
and
ideologies
about
the
future
of
humanity .
Quantum
computing
is
a
multidisciplinary
field
that
focuses
on
building
quantum
algorithms.
These
focus
on
improving
computational
tasks
within
AI
along
with
related
fields
like
machine
learning.
As
of
now,
the
concept
of
quantum-enhanced
AI
algorithms
remains
in
the
abstract
research
realm.
Advancements
in
the
technology
of
autonomy
will
create
new
opportunities
in
medicine,
scientific
research,
and
space
exploration.
One
thing
is
for
sure,
human
lives
will
not
be
the
same
with
each
milestone
achieved
in
AI
from
both
technology
benefits
and
associated
risks.
Non-technical
explanation
of
deep
learning
Let
us
start
with
neural
networks
and
their
relation
to
deep
learning.
Figure
2.5
describes
a
neural
network
when
the
number
of
hidden
layers
is
1:
The
“deep”
in
deep
learning
refers
to
the
depth
of
or
multiple
hidden
layers
in
a
neural
network.
A
deep
learning
algorithm
is,
therefore,
a
neural
network
that
consists
of
more
than
three
layers,
inclusive
of
the
inputs
and
the
output
layers.
Figure
2.6
describes
a
typical
deep
learning
system
or
a
deep
neural
network:
Deep
neural
networks
flow
in
one
direction
only
from
input
to
output.
However ,
they
can
also
train
your
model
through
backpropagation,
that
is,
move
in
opposite
directions
from
output
to
input.
Backpropagation
allows
us
to
calculate
and
attribute
the
error
associated
with
each
neuron,
allowing
us
to
adjust
and
fit
the
algorithm
appropriately .
Commonly
used
deep
learning
algorithm
explained
Let
us
also
understand
Recurrent
Neural
Network
(RNN)
,
which
is
the
underlying
methodology
for
applications
such
as:
●
Language
modeling
and
generating
text
Speech
recognition
●
Machine
translation
●
Image
recognition,
face
detection
●
Time
series
forecasting
In
a
traditional
neural
network
(which
we
learned
in
Chapter
1,
Introduction
to
AI),
inputs
and
outputs
are
independent
of
each
other .
Whereas
RNN
is
a
type
of
neural
network
where
the
output
from
the
previous
step
is
taken
in
as
input
to
the
current
step,
that
is,
output
at
a
specific
stage
is
dependent
on
output
from
its
previous
stage.
In
the
case
of
a
sentence,
a
word
is
predicted
based
on
previous
words
to
give
a
particular
meaning
to
the
sentence.
As
such,
there
is
a
need
to
remember
previous
words.
RNN
solves
such
issues
with
a
hidden
layer
that
remembers
the
information
about
a
sequence.
It
has
a
memory
that
remembers
the
past
sequence.
Since
the
same
parameters
are
applied
to
each
input,
the
complexity
is
reduced,
unlike
in
neural
networks.
Let
us
understand
how
these
RNNs
work.
For
this,
we
first
understand
the
flow
of
a
deep
neural
network.
In
our
example,
we
assume
one
input,
three
hidden,
and
one
output
layer
for
a
deep
neural
network,
with
each
hidden
layer
having
its
own
weights
and
biases
represented
as
(wl,
bl),
where
‘l’
takes
values
1,
2,
and
3
for
respective
layers.
These
layers
are
totally
independent
of
each
other;
that
is,
they
do
not
learn
or
memorize
the
previous
outputs.
Figure
2.7
shows
such
a
deep
neural
network:While
in
RNN,
all
layers
have
the
same
weight
and
biases,
thereby
reducing
the
complexity
of
parameters.
All
these
layers
are
then
joined
together
in
a
single
recurrent
layer .
This
converts
independent
activations
into
dependent
activations
and
memorizes
each
previous
output
by
providing
each
output
as
input
to
the
next
hidden
layer .
Figure
2.8
displays
this
for
the
recurrent
neural
network:
Advantages
of
Recurrent
Neural
Network
●
It
is
useful
in
time
series
prediction
because
of
its
feature
of
memorizing
previous
output.
●
RNNs
are
even
used
with
convolutional
layers
(the
main
building
block
of
a
convolutional
neural
network
that
analyzes
visual
imagery)
to
extend
the
effective
pixel
neighborhood.
Conclusion
AI
is
already
being
adopted
by
various
industries
and
is
available
for
access
to
all
in
some
form
or
the
other .
The
future
will
see
far
deeper
adoption
of
AI
with
its
own
challenges
and
risks
like
any
other
technology
poses.
Hence
factors
like
ethics
and
governance
become
priorities
while
achieving
advancements
in
areas
of
AI.
In
the
next
chapter ,
we
will
learn
the
application
of
mathematics
in
AI.
We
will
also
revisit
the
basics
of
linear
algebra,
statistics,
and
data
visualization
in
terms
of
graphs
and
representation
in
mathematical
formulas.
